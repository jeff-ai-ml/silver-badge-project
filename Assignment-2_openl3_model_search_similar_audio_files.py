# -*- coding: utf-8 -*-
"""OpenL3_Model_Search_similar_audio_files.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VvCyXK8pnzl9yklgB3Pb5sGZVmaacYTF
"""

import torch
import torchaudio
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import os
import glob
import matplotlib.pyplot as plt
from IPython.display import Audio, display

"""# --- 1. Install necessary libraries ---"""

print("Installing required libraries...")
# Install libsndfile for audio processing
!apt-get update && apt-get install -y libsndfile1
# Install OpenL3 (which will install TensorFlow as a dependency)
!pip install openl3 torchaudio soundfile scikit-learn matplotlib

"""# --- 2. Load the OpenL3 model and define parameters ---"""

import openl3

# Preload the OpenL3 model to avoid re-loading for each file
# This loads the default 'music' content type, 'mel128' input representation, 512 embedding size
print(f"Loading OpenL3 model (content_type='music', embedding_size=512, target_sr=48000)...")
openl3_model = openl3.models.load_audio_embedding_model(
    input_repr='mel128',
    content_type='music',
    embedding_size=512
)
print("OpenL3 model loaded.")

# Define common audio processing parameters
# OpenL3 can handle various SRs, but 48kHz is common.
# OpenL3 internally resamples to its required SR (e.g., 48kHz to 44.1kHz for some models, or 16kHz for others).
# Passing the original SR to openl3.get_audio_embedding is often sufficient.
# However, explicit resampling beforehand ensures consistency and control.
TARGET_SAMPLING_RATE = 48000 # Keep a high sample rate for initial loading
MONO_AUDIO = True

# --- Function Definition: get_audio_openl3_embedding ---
def get_audio_openl3_embedding(audio_path, openl3_model, target_sr, mono):
    """Loads audio with torchaudio, processes it, and gets OpenL3 embedding."""
    try:
        # Load audio using torchaudio
        waveform, sr = torchaudio.load(audio_path)

        # Resample if necessary using torchaudio
        if sr != target_sr:
            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)
            waveform = resampler(waveform)

        # Convert to mono if requested and if it's currently multi-channel
        if mono and waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)

        # Ensure it's 1D (samples,) if mono.
        if waveform.shape[0] == 1:
            waveform = waveform.squeeze(0)

        # IMPORTANT: Convert PyTorch tensor to NumPy array (on CPU) before passing to OpenL3
        # OpenL3's get_audio_embedding expects a NumPy array.
        audio_np = waveform.cpu().numpy()

        # OpenL3's get_audio_embedding returns embeddings and timestamps
        embeddings, timestamps = openl3.get_audio_embedding(
            audio_np, target_sr, # Pass the NumPy array and its sample rate
            model=openl3_model,
            input_repr='mel128',
            content_type='music',
            embedding_size=512
        )

        # For song-level embedding, average over time frames
        song_embedding = np.mean(embeddings, axis=0)

        return song_embedding

    except Exception as e:
        print(f"Could not process audio {os.path.basename(audio_path)}: {e}")
        return None

"""# --- START OF MAIN SCRIPT LOGIC ---

# --- 3. Prepare your uploaded audio files ---
"""

audio_dir = "/content/uploaded_songs"
os.makedirs(audio_dir, exist_ok=True)

uploaded_audio_paths = glob.glob(os.path.join(audio_dir, "*.mp3"))
uploaded_audio_paths.sort()

if not uploaded_audio_paths:
    print(f"Error: No MP3 files found in '{audio_dir}'.")
    print("Please ensure you have manually uploaded your songs to this directory in Colab.")
    exit()

print(f"Found {len(uploaded_audio_paths)} uploaded songs:")
for path in uploaded_audio_paths:
    print(f"- {path}")

"""# --- 4. Generate embeddings for all uploaded songs using OpenL3 ---"""

print(f"\nGenerating embeddings for uploaded songs (target SR: {TARGET_SAMPLING_RATE})...")
uploaded_embeddings = []
valid_uploaded_audio_paths = []

for audio_path in uploaded_audio_paths:
    embedding = get_audio_openl3_embedding(audio_path, openl3_model, TARGET_SAMPLING_RATE, MONO_AUDIO)
    if embedding is not None:
        uploaded_embeddings.append(embedding)
        valid_uploaded_audio_paths.append(audio_path)
    else:
        print(f"Skipping {os.path.basename(audio_path)} due to embedding error.")

uploaded_embeddings = np.array(uploaded_embeddings)

if uploaded_embeddings.size == 0:
    print("No valid audio embeddings could be generated. Exiting.")
    exit()

print(f"Generated embeddings for {uploaded_embeddings.shape[0]} songs, each with dimension {uploaded_embeddings.shape[1]}.")

# --- 5. Define your query song ---
if valid_uploaded_audio_paths:
    query_song_path = valid_uploaded_audio_paths[0]
else:
    print("Cannot set query song as no valid uploaded songs were found.")
    exit()

if not os.path.exists(query_song_path):
    print(f"\nError: Query song '{query_song_path}' not found. This should not happen if selected from valid_uploaded_audio_paths.")
    exit()

print(f"\nQuerying with song: {query_song_path}")

"""# --- 6. Generate embedding for the query song ---"""

query_dir = "/content/query_song"

# Get a list of all MP3 file paths from the directory
uploaded_query_paths = glob.glob(os.path.join(query_dir, "*.mp3"))
uploaded_query_paths.sort() # Sort for consistent order
uploaded_query_paths

query_song_path = uploaded_query_paths[5]
query_song_path

"""# --- 6. Generate embedding for the query song ---"""

query_embedding = get_audio_openl3_embedding(query_song_path, openl3_model, TARGET_SAMPLING_RATE, MONO_AUDIO)

if query_embedding is None:
    print("Failed to generate embedding for the query song. Exiting.")
    exit()
else:
  print("Embedding for query song is done!")
  print(query_embedding)

"""# --- 7. Perform similarity search (Cosine Similarity) ---"""

query_embedding_reshaped = query_embedding.reshape(1, -1)
similarities = cosine_similarity(query_embedding_reshaped, uploaded_embeddings)[0]

"""# --- 8. Rank and display results ---"""

results = []
for i, score in enumerate(similarities):
    results.append((score, valid_uploaded_audio_paths[i]))

results.sort(key=lambda x: x[0], reverse=True)

print("\n--- Semantic Audio Search Results (Highest Similarity First) ---")
print(f"Query Song: {os.path.basename(query_song_path)}")
display(Audio(query_song_path))

print("\nSimilar Songs:")
for i, (score, path) in enumerate(results):
    print(f"{i+1}. Song: {os.path.basename(path)}, Similarity: {score:.4f}")
    display(Audio(path))